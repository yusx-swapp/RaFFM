{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RaFFM for Segment Anything (SAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/work/yusx/miniconda3/envs/raffm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import SamModel, SamProcessor, SamVisionConfig\n",
    "from raffm import RaFFM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SAM via SamModel use transformers models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SamModel.from_pretrained(\"facebook/sam-vit-huge\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert original SAM to scalable RaFFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FM number of parameters: 635.177828\n"
     ]
    }
   ],
   "source": [
    "## Subnetwork space\n",
    "elastic_config = {\n",
    "    \"atten_out_space\": [512, 768, 1280], # keep attention layer fixed\n",
    "    \"inter_hidden_space\": [512, 1024, 1280, 2048],\n",
    "    \"residual_hidden_space\": [1024, 1280, 2048],\n",
    "}\n",
    "raffm_model = RaFFM(model.to(\"cpu\"),elastic_config=elastic_config)\n",
    "print(\"Original FM number of parameters:\",raffm_model.total_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sample a subnetwork from original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subnetwork params 256.379748\n"
     ]
    }
   ],
   "source": [
    "#Random sample a scaled FM\n",
    "submodel, params, config = raffm_model.random_resource_aware_model()\n",
    "print(\"subnetwork params\",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SamModel' object has no attribute 'save_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msubmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_state_dict\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ckpt/ckpts.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(config,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ckpt/arc_config.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/export/work/yusx/miniconda3/envs/raffm/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SamModel' object has no attribute 'save_state_dict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(submodel.state_dict(),\"./ckpt/ckpts.pt\")\n",
    "torch.save(config,\"./ckpt/arc_config.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_config = torch.load(\"./ckpt/arc_config.pt\")\n",
    "loaded_net,_ = raffm_model.resource_aware_model(sub_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SamModel(\n",
       "  (shared_image_embedding): SamPositionalEmbedding()\n",
       "  (vision_encoder): SamVisionEncoder(\n",
       "    (patch_embed): SamPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 1280, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (3): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (4): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (5): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=512, bias=True)\n",
       "          (lin2): Linear(in_features=512, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (6): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=512, bias=True)\n",
       "          (lin2): Linear(in_features=512, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (7): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (8): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (9): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (10): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=512, bias=True)\n",
       "          (lin2): Linear(in_features=512, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (11): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (12): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (13): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=512, bias=True)\n",
       "          (lin2): Linear(in_features=512, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (14): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (15): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (16): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (17): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (18): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (19): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (20): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (21): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (22): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (23): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (lin2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (24-25): 2 x SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (26): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (27): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (28): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (29): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=2048, bias=True)\n",
       "          (lin2): Linear(in_features=2048, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (30): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=512, bias=True)\n",
       "          (lin2): Linear(in_features=512, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (31): SamVisionLayer(\n",
       "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): SamVisionAttention(\n",
       "          (qkv): Linear(in_features=1280, out_features=1536, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): SamMLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "          (lin2): Linear(in_features=1024, out_features=1280, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): SamVisionNeck(\n",
       "      (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (layer_norm1): SamLayerNorm()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer_norm2): SamLayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): SamPromptEncoder(\n",
       "    (shared_embedding): SamPositionalEmbedding()\n",
       "    (mask_embed): SamMaskEmbedding(\n",
       "      (activation): GELUActivation()\n",
       "      (conv1): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv2): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layer_norm1): SamLayerNorm()\n",
       "      (layer_norm2): SamLayerNorm()\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "    (point_embed): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): SamMaskDecoder(\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (transformer): SamTwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x SamTwoWayAttentionBlock(\n",
       "          (self_attn): SamAttention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): SamAttention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SamMLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (layer_norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (layer_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): SamAttention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): SamAttention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (layer_norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (upscale_conv1): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (upscale_conv2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (upscale_layer_norm): SamLayerNorm()\n",
       "    (activation): GELU(approximate='none')\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x SamFeedForward(\n",
       "        (activation): ReLU()\n",
       "        (proj_in): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_out): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): SamFeedForward(\n",
       "      (activation): ReLU()\n",
       "      (proj_in): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (proj_out): Linear(in_features=256, out_features=4, bias=True)\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloaded_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./ckpt/model.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/export/work/yusx/miniconda3/envs/raffm/lib/python3.10/site-packages/torch/nn/modules/module.py:2103\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;124;03mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;124;03mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2105\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2106\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'str'>."
     ]
    }
   ],
   "source": [
    "loaded_net.load_state_dict(torch.load(\"./ckpt/pytorch_model.bin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample a new subnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subnetwork params 224.267108\n"
     ]
    }
   ],
   "source": [
    "#Random sample a scaled FM\n",
    "submodel, params, config = raffm_model.random_resource_aware_model()\n",
    "print(\"subnetwork params\",params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference the subnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "img_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")\n",
    "input_points = [[[450, 600]]]  # 2D location of a window in the image\n",
    "\n",
    "inputs = processor(raw_image, input_points=input_points, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = submodel(**inputs)\n",
    "\n",
    "masks = processor.image_processor.post_process_masks(\n",
    "    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n",
    ")\n",
    "scores = outputs.iou_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4543, 0.5698, 0.5852]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
