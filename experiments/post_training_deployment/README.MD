# Post-training High-performance Resource-aware Model deployment

## Experiment Goal

In this experiment we show:

**Post federated training, FMs trained by our method is scalable, and we can generate surprisingly large number of scaled FMs (> $10^{10}$) with out further training**

Such scaled FMs can fit different resource-constraints at the edge while maintaining the same level of accuracy.

## Reproduce the Experiments

You can find out the experiments on the jupyter notebook: [fm_scaling.ipynb](./fm_scaling.ipynb)

## Results
